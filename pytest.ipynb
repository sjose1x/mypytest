{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_.py\n",
    "def plusone(x):\n",
    "    return x+1\n",
    "def test_one():\n",
    "    assert plusone(3) == 5\n",
    "def test_2():\n",
    "    #comparison\n",
    "    assert 'foo 1 bar' == 'foo 2 bar'\n",
    "\n",
    "def test_3():\n",
    "    #comparison2\n",
    "    a = 'a'*100+'1'+'b'*100\n",
    "    b = 'a'*100+'2'+'b'*100\n",
    "    assert a == b\n",
    "\n",
    "def test_4():\n",
    "    #comparison2\n",
    "    a = set([1,2,3])\n",
    "    b = set([1,3,4])\n",
    "    assert a == b\n",
    "    \n",
    "def test_5():\n",
    "    #comparison2\n",
    "    a = set([1,2,3])\n",
    "    b = set([1,3,4])\n",
    "    assert a == b\n",
    "def test_6():\n",
    "    a={'a':'b'}\n",
    "    b={'x':'d'}\n",
    "    assert a == b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 2.7.10 -- py-1.4.25 -- pytest-2.6.3\n",
      "collected 6 items \n",
      "\u001b[0m\n",
      "test_.py FFFFFF\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "___________________________________ test_one ___________________________________\n",
      "\n",
      "\u001b[1m    def test_one():\u001b[0m\n",
      "\u001b[1m>       assert plusone(3) == 5\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 4 == 5\u001b[0m\n",
      "\u001b[1m\u001b[31mE        +  where 4 = plusone(3)\u001b[0m\n",
      "\n",
      "test_.py:4: AssertionError\n",
      "____________________________________ test_2 ____________________________________\n",
      "\n",
      "\u001b[1m    def test_2():\u001b[0m\n",
      "\u001b[1m        #comparison\u001b[0m\n",
      "\u001b[1m>       assert 'foo 1 bar' == 'foo 2 bar'\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 'foo 1 bar' == 'foo 2 bar'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         - foo 1 bar\u001b[0m\n",
      "\u001b[1m\u001b[31mE         ?     ^\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + foo 2 bar\u001b[0m\n",
      "\u001b[1m\u001b[31mE         ?     ^\u001b[0m\n",
      "\n",
      "test_.py:7: AssertionError\n",
      "____________________________________ test_3 ____________________________________\n",
      "\n",
      "\u001b[1m    def test_3():\u001b[0m\n",
      "\u001b[1m        #comparison2\u001b[0m\n",
      "\u001b[1m        a = 'a'*100+'1'+'b'*100\u001b[0m\n",
      "\u001b[1m        b = 'a'*100+'2'+'b'*100\u001b[0m\n",
      "\u001b[1m>       assert a == b\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert 'aaaaaaaaaaaa...bbbbbbbbbbbbb' == 'aaaaaaaaaaaaa...bbbbbbbbbbbbb'\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Skipping 90 identical leading characters in diff, use -v to show\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Skipping 91 identical trailing characters in diff, use -v to show\u001b[0m\n",
      "\u001b[1m\u001b[31mE         - aaaaaaaaaa1bbbbbbbbb\u001b[0m\n",
      "\u001b[1m\u001b[31mE         ?           ^\u001b[0m\n",
      "\u001b[1m\u001b[31mE         + aaaaaaaaaa2bbbbbbbbb\u001b[0m\n",
      "\u001b[1m\u001b[31mE         ?           ^\u001b[0m\n",
      "\n",
      "test_.py:13: AssertionError\n",
      "____________________________________ test_4 ____________________________________\n",
      "\n",
      "\u001b[1m    def test_4():\u001b[0m\n",
      "\u001b[1m        #comparison2\u001b[0m\n",
      "\u001b[1m        a = set([1,2,3])\u001b[0m\n",
      "\u001b[1m        b = set([1,3,4])\u001b[0m\n",
      "\u001b[1m>       assert a == b\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert set([1, 2, 3]) == set([1, 3, 4])\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Extra items in the left set:\u001b[0m\n",
      "\u001b[1m\u001b[31mE         2\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Extra items in the right set:\u001b[0m\n",
      "\u001b[1m\u001b[31mE         4\u001b[0m\n",
      "\n",
      "test_.py:19: AssertionError\n",
      "____________________________________ test_5 ____________________________________\n",
      "\n",
      "\u001b[1m    def test_5():\u001b[0m\n",
      "\u001b[1m        #comparison2\u001b[0m\n",
      "\u001b[1m        a = set([1,2,3])\u001b[0m\n",
      "\u001b[1m        b = set([1,3,4])\u001b[0m\n",
      "\u001b[1m>       assert a == b\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert set([1, 2, 3]) == set([1, 3, 4])\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Extra items in the left set:\u001b[0m\n",
      "\u001b[1m\u001b[31mE         2\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Extra items in the right set:\u001b[0m\n",
      "\u001b[1m\u001b[31mE         4\u001b[0m\n",
      "\n",
      "test_.py:25: AssertionError\n",
      "____________________________________ test_6 ____________________________________\n",
      "\n",
      "\u001b[1m    def test_6():\u001b[0m\n",
      "\u001b[1m        a={'a':'b'}\u001b[0m\n",
      "\u001b[1m        b={'x':'d'}\u001b[0m\n",
      "\u001b[1m>       assert a == b\u001b[0m\n",
      "\u001b[1m\u001b[31mE       assert {'a': 'b'} == {'x': 'd'}\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Left contains more items:\u001b[0m\n",
      "\u001b[1m\u001b[31mE         {'a': 'b'}\u001b[0m\n",
      "\u001b[1m\u001b[31mE         Right contains more items:\u001b[0m\n",
      "\u001b[1m\u001b[31mE         {'x': 'd'}\u001b[0m\n",
      "\n",
      "test_.py:29: AssertionError\n",
      "\u001b[1m\u001b[31m=========================== 6 failed in 0.04 seconds ===========================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exception Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_exp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_exp.py\n",
    "import pytest\n",
    "def f():\n",
    "    raise SystemExit(1)\n",
    "def test_exception():\n",
    "    with pytest.raises(SystemExit):\n",
    "        f()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixtures (Setup & Teardown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@pytest.fixture(autouse=True) act as setup/teardown without explicit request by test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_fixtures.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_fixtures.py\n",
    "import pytest\n",
    "\n",
    "class Person:\n",
    "    def greet(self):\n",
    "        print \"greet called ...\"\n",
    "        return \"Hello World\"\n",
    "@pytest.fixture\n",
    "def person():\n",
    "    return Person()\n",
    "def test_fix(person):\n",
    "    greeting = person.greet()\n",
    "    assert greeting == \"Hi World\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mock(spec=SomeClass) #spec => raise an exception if I'm accessing an attribute which is not there in 'SomeClass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mock_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mock_example.py\n",
    "class DB:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def persist(self, person):\n",
    "        pass\n",
    "    \n",
    "class Person:\n",
    "    def __init__(self, db, name):\n",
    "        self.db = db\n",
    "        self.name = name\n",
    "        \n",
    "    def save(self):\n",
    "        self.db.persist(self)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_mock.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_mock.py\n",
    "import pytest\n",
    "from mock import MagicMock\n",
    "from mock_example import Person, DB\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_db():\n",
    "    return MagicMock(spec=DB)\n",
    "\n",
    "def test_save_persist_to_db(mock_db):\n",
    "    sashi = Person(\"Sashi\", mock_db)\n",
    "    sashi.save()\n",
    "    mock_db.persist.assert_called_with(sashi)\n",
    "    \n",
    "def test_save_persist_to_db(mock_db):\n",
    "    mock_db.persist.assert_called_with()\n",
    "    \n",
    "def test_called_with_other_agr(mock_db):\n",
    "    mock_db.persist(1,2,3)\n",
    "    mock_db.persist.assert_called_with()\n",
    "    \n",
    "def test_any_call_mock_db(mock_db):\n",
    "    mock_db.persist(1)\n",
    "    mock_db.persist(3)\n",
    "    #assert_called_with() will check for the last call\n",
    "    mock_db.persist.assert_any_call(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!py.test test_mock.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_mock.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile weather_service.py\n",
    "import random\n",
    "\n",
    "class WeatherService:\n",
    "    def barometer(self):\n",
    "        return random.choise(['rising','falling'])#Non deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting forecastor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile forecastor.py\n",
    "\n",
    "import random\n",
    "\n",
    "class WeatherService:\n",
    "    def barometer(self):\n",
    "        return random.choise(['rising','falling'])#Non deterministic\n",
    "\n",
    "class ForeCaster:\n",
    "    def __init__(self, weatherservice):\n",
    "        self.weatherservice = weatherservice\n",
    "    \n",
    "    def forecast(self):\n",
    "        reading = self.weatherservice.barometer()\n",
    "        forcast_dict = dict(\n",
    "        rising ='Going to Rain',\n",
    "        falling = 'Looks Clear'\n",
    "        )\n",
    "        return forcast_dict[reading]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_mock_ws.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_mock_ws.py\n",
    "import pytest\n",
    "from mock import MagicMock\n",
    "from forecastor import ForeCaster, WeatherService\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_ws():\n",
    "    return MagicMock(spec=WeatherService)\n",
    "\n",
    "def test_rain_when_barometer_rising(mock_ws):\n",
    "    forecaster = ForeCaster(mock_ws)\n",
    "    mock_ws.barometer.return_value = 'rising'\n",
    "    assert forecaster.forecast() == 'Going to Rain'\n",
    "#instead of two test cases for rising and falling\n",
    "@pytest.mark.parametrize(\"reading, expected_forecast\",\n",
    "                         [('rising', 'Going to Rain'),\n",
    "                          ('falling','Looks Clear')])\n",
    "def test_forecast(reading, expected_forecast, mock_ws):\n",
    "    forecaster = ForeCaster(mock_ws)\n",
    "    mock_ws.barometer.return_value = reading\n",
    "    assert forecaster.forecast() == expected_forecast\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\r\n",
      "platform darwin -- Python 2.7.10 -- py-1.4.25 -- pytest-2.6.3 -- //anaconda/bin/python\r\n",
      "\u001b[1m\r",
      "collecting 0 items\u001b[0m\u001b[1m\r",
      "collecting 3 items\u001b[0m\u001b[1m\r",
      "collected 3 items \r\n",
      "\u001b[0m\r\n",
      "test_mock_ws.py::test_rain_when_barometer_rising \u001b[32mPASSED\u001b[0m\r\n",
      "test_mock_ws.py::test_forecast[rising-Going to Rain] \u001b[32mPASSED\u001b[0m\r\n",
      "test_mock_ws.py::test_forecast[falling-Looks Clear] \u001b[32mPASSED\u001b[0m\r\n",
      "\r\n",
      "\u001b[32m\u001b[1m=========================== 3 passed in 0.02 seconds ===========================\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!py.test -v test_mock_ws.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MonkeyPatching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its a predefined fixture\n",
    "\n",
    "use monkeypatch.setattr() for patch value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing forecastor2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile forecastor2.py\n",
    "\n",
    "import random\n",
    "\n",
    "class WeatherService:\n",
    "    def barometer(self):\n",
    "        return random.choise(['rising','falling'])#Non deterministic\n",
    "\n",
    "class ForeCaster:\n",
    "    def __init__(self):\n",
    "        self.weatherservice = WeatherService()\n",
    "    \n",
    "    def forecast(self):\n",
    "        reading = self.weatherservice.barometer()\n",
    "        forcast_dict = dict(\n",
    "        rising ='Going to Rain',\n",
    "        falling = 'Looks Clear'\n",
    "        )\n",
    "        return forcast_dict[reading]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_mock_ws2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_mock_ws2.py\n",
    "import pytest\n",
    "from mock import MagicMock\n",
    "from forecastor import ForeCaster, WeatherService\n",
    "\n",
    "@pytest.fixture\n",
    "def mock_ws():\n",
    "    return MagicMock(spec=WeatherService)\n",
    "\n",
    "def test_rain_when_barometer_rising(monkeypatch, mock_ws):\n",
    "    WS = MagicMock(return_value=mock_ws)\n",
    "    monkeypatch.setattr('forecastor.WeatherService',WS)\n",
    "    forecaster = ForeCaster(mock_ws)\n",
    "    mock_ws.barometer.return_value = 'rising'\n",
    "    assert forecaster.forecast() == 'Going to Rain'\n",
    "#instead of two test cases for rising and falling\n",
    "@pytest.mark.parametrize(\"reading, expected_forecast\",\n",
    "                         [('rising', 'Going to Rain'),\n",
    "                          ('falling','Look3s Clear')])\n",
    "def test_forecast(reading, expected_forecast, monkeypatch, mock_ws):\n",
    "    WS = MagicMock(return_value=mock_ws)\n",
    "    monkeypatch.setattr('forecastor.WeatherService',WS)\n",
    "    forecaster = ForeCaster(mock_ws)\n",
    "    mock_ws.barometer.return_value = reading\n",
    "    assert forecaster.forecast() == expected_forecast\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!py.test -v test_mock_ws2.py --ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print \"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
